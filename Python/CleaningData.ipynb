{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "341f598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the necessary libraries\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e0cd990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "BASE_DIR = os.path.abspath(\"..\")                      # github_repo/\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\", \"raw\")       # github_repo/data/raw\n",
    "DB_PATH = os.path.join(BASE_DIR, \"insurance.db\")       # github_repo/insurance.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee8ddc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect back to the database\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7a51a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the query to just select my table from the database\n",
    "start = time.time()\n",
    "df=pd.read_sql(\"SELECT * FROM combined_data_pre_cleaning\",conn)\n",
    "end = time.time()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e976c052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query returned 2,280,250 rows x 22 columns in 21.11 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INDIVIDUAL_ID</th>\n",
       "      <th>ADDRESS_ID</th>\n",
       "      <th>CURR_ANN_AMT</th>\n",
       "      <th>DAYS_TENURE</th>\n",
       "      <th>CUST_ORIG_DATE</th>\n",
       "      <th>age_in_years</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>STREET_ADDRESS</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>Churn</th>\n",
       "      <th>income</th>\n",
       "      <th>ACCT_SUSPD_DATE</th>\n",
       "      <th>HAS_CHILDREN</th>\n",
       "      <th>LENGTH_OF_RESIDENCE</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>HOME_MARKET_VALUE</th>\n",
       "      <th>HOME_OWNER</th>\n",
       "      <th>COLLEGE_DEGREE</th>\n",
       "      <th>GOOD_CREDIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>660.852375</td>\n",
       "      <td>2810.0</td>\n",
       "      <td>2015-03-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.213000e+11</td>\n",
       "      <td>5.213000e+11</td>\n",
       "      <td>1194.050321</td>\n",
       "      <td>6291.0</td>\n",
       "      <td>2005-09-11</td>\n",
       "      <td>66.387</td>\n",
       "      <td>32.964555</td>\n",
       "      <td>-96.819410</td>\n",
       "      <td>312 Austin Plains</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80372.176</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.801</td>\n",
       "      <td>None</td>\n",
       "      <td>500000 - 749999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.213000e+11</td>\n",
       "      <td>5.213000e+11</td>\n",
       "      <td>837.936100</td>\n",
       "      <td>4496.0</td>\n",
       "      <td>2010-08-11</td>\n",
       "      <td>58.968</td>\n",
       "      <td>32.964555</td>\n",
       "      <td>-96.819410</td>\n",
       "      <td>312 Austin Plains</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125000.000</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>Single</td>\n",
       "      <td>500000 - 749999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.213000e+11</td>\n",
       "      <td>5.213000e+11</td>\n",
       "      <td>1141.116276</td>\n",
       "      <td>6291.0</td>\n",
       "      <td>2005-09-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.600787</td>\n",
       "      <td>-97.101485</td>\n",
       "      <td>USNS Lee</td>\n",
       "      <td>Mansfield</td>\n",
       "      <td>TX</td>\n",
       "      <td>Tarrant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.213000e+11</td>\n",
       "      <td>5.213000e+11</td>\n",
       "      <td>695.119342</td>\n",
       "      <td>6291.0</td>\n",
       "      <td>2005-09-11</td>\n",
       "      <td>64.641</td>\n",
       "      <td>32.563342</td>\n",
       "      <td>-97.058826</td>\n",
       "      <td>3622 Robert Ridges Suite 152</td>\n",
       "      <td>Mansfield</td>\n",
       "      <td>TX</td>\n",
       "      <td>Tarrant</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70000.000</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.000</td>\n",
       "      <td>Married</td>\n",
       "      <td>125000 - 149999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   INDIVIDUAL_ID    ADDRESS_ID  CURR_ANN_AMT  DAYS_TENURE CUST_ORIG_DATE  \\\n",
       "0            NaN           NaN    660.852375       2810.0     2015-03-24   \n",
       "1   2.213000e+11  5.213000e+11   1194.050321       6291.0     2005-09-11   \n",
       "2   2.213000e+11  5.213000e+11    837.936100       4496.0     2010-08-11   \n",
       "3   2.213000e+11  5.213000e+11   1141.116276       6291.0     2005-09-11   \n",
       "4   2.213000e+11  5.213000e+11    695.119342       6291.0     2005-09-11   \n",
       "\n",
       "   age_in_years   LATITUDE  LONGITUDE                STREET_ADDRESS  \\\n",
       "0           NaN        NaN        NaN                          None   \n",
       "1        66.387  32.964555 -96.819410             312 Austin Plains   \n",
       "2        58.968  32.964555 -96.819410             312 Austin Plains   \n",
       "3           NaN  32.600787 -97.101485                      USNS Lee   \n",
       "4        64.641  32.563342 -97.058826  3622 Robert Ridges Suite 152   \n",
       "\n",
       "        CITY STATE   COUNTY  Churn      income ACCT_SUSPD_DATE  HAS_CHILDREN  \\\n",
       "0       None  None     None    NaN         NaN            None           NaN   \n",
       "1     Dallas    TX   Dallas    NaN   80372.176            None           0.0   \n",
       "2     Dallas    TX   Dallas    0.0  125000.000            None           1.0   \n",
       "3  Mansfield    TX  Tarrant    NaN         NaN            None           NaN   \n",
       "4  Mansfield    TX  Tarrant    0.0   70000.000            None           1.0   \n",
       "\n",
       "   LENGTH_OF_RESIDENCE marital_status HOME_MARKET_VALUE  HOME_OWNER  \\\n",
       "0                  NaN           None              None         NaN   \n",
       "1                6.801           None   500000 - 749999         0.0   \n",
       "2                2.000         Single   500000 - 749999         1.0   \n",
       "3                  NaN           None              None         NaN   \n",
       "4                7.000        Married   125000 - 149999         1.0   \n",
       "\n",
       "   COLLEGE_DEGREE  GOOD_CREDIT  \n",
       "0             NaN          NaN  \n",
       "1             1.0          1.0  \n",
       "2             0.0          1.0  \n",
       "3             NaN          NaN  \n",
       "4             1.0          1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm the size of my df is what I would expect\n",
    "print(f\"\\nQuery returned {df.shape[0]:,} rows x {df.shape[1]} columns in {end - start:.2f} seconds\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0438d646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dates to type datetime\n",
    "# df['ACCT_SUSPD_DATE'] = pd.to_datetime(df['ACCT_SUSPD_DATE'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb2d3ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logic applied here: if there is a termination date, then we know there is churn happening\n",
    "# df.loc[df['Churn'].isna() & df['ACCT_SUSPD_DATE'].notna(),'Churn']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c012f5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2280250 entries, 0 to 2280249\n",
      "Data columns (total 22 columns):\n",
      " #   Column               Dtype  \n",
      "---  ------               -----  \n",
      " 0   INDIVIDUAL_ID        float64\n",
      " 1   ADDRESS_ID           float64\n",
      " 2   CURR_ANN_AMT         float64\n",
      " 3   DAYS_TENURE          float64\n",
      " 4   CUST_ORIG_DATE       object \n",
      " 5   age_in_years         float64\n",
      " 6   LATITUDE             float64\n",
      " 7   LONGITUDE            float64\n",
      " 8   STREET_ADDRESS       object \n",
      " 9   CITY                 object \n",
      " 10  STATE                object \n",
      " 11  COUNTY               object \n",
      " 12  Churn                float64\n",
      " 13  income               float64\n",
      " 14  ACCT_SUSPD_DATE      object \n",
      " 15  HAS_CHILDREN         float64\n",
      " 16  LENGTH_OF_RESIDENCE  float64\n",
      " 17  marital_status       object \n",
      " 18  HOME_MARKET_VALUE    object \n",
      " 19  HOME_OWNER           float64\n",
      " 20  COLLEGE_DEGREE       float64\n",
      " 21  GOOD_CREDIT          float64\n",
      "dtypes: float64(14), object(8)\n",
      "memory usage: 382.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Let's confirm the data types of each of my variables of interest\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48c58bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table of 'Individual_ID' duplicate column:\n",
      " Series([], Name: count, dtype: int64)\n",
      "Number of dupliacted customers:  0\n"
     ]
    }
   ],
   "source": [
    "# Let's make sure that there are no duplicate counts for individual ID's\n",
    "quantity = df['INDIVIDUAL_ID'].value_counts()\n",
    "duplicates_in_name = quantity[quantity > 1]\n",
    "print(\"Table of 'Individual_ID' duplicate column:\\n\", duplicates_in_name)\n",
    "\n",
    "duplicate_rows_count = df[df.duplicated(subset=[\"INDIVIDUAL_ID\"],keep=False)].shape[0]\n",
    "print(\"Number of dupliacted customers: \",duplicate_rows_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9804fb3f",
   "metadata": {},
   "source": [
    "The cell above shows that there are no duplicates in the individual_id column which is good to set this as the true value for all of our modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "809b5b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table of 'ADDRESS_ID' duplicate column:\n",
      " ADDRESS_ID\n",
      "5.213006e+11    468\n",
      "5.213005e+11    442\n",
      "5.213009e+11    336\n",
      "5.213002e+11    332\n",
      "5.213004e+11    308\n",
      "               ... \n",
      "5.213010e+11      2\n",
      "5.213003e+11      2\n",
      "5.213000e+11      2\n",
      "5.213000e+11      2\n",
      "5.213000e+11      2\n",
      "Name: count, Length: 394769, dtype: int64\n",
      "Number of duplicated addresses:  1,138,397\n"
     ]
    }
   ],
   "source": [
    "# I want to get an idea of how many duplicates there are for address id's\n",
    "quantity = df['ADDRESS_ID'].value_counts()\n",
    "duplicates_in_name = quantity[quantity > 1]\n",
    "print(\"Table of 'ADDRESS_ID' duplicate column:\\n\", duplicates_in_name)\n",
    "\n",
    "duplicate_rows_count = df[df.duplicated(subset=[\"ADDRESS_ID\"],keep=False)].shape[0]\n",
    "print(\"Number of duplicated addresses: \",\"{:,}\".format(duplicate_rows_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f401bc49",
   "metadata": {},
   "source": [
    "As we can see, there are many duplicated addresses with multiple individual id's living at the same address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4aeabfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm going to create a helper function to help me see how many missing values I have in my code\n",
    "def missing_summary(df):\n",
    "    pd.set_option('display.max_columns',None)\n",
    "    print(pd.DataFrame({\n",
    "        'Missing Values': df.isna().sum(),\n",
    "        'Percentage': (df.isna().sum() / len(df))*100\n",
    "    }))\n",
    "\n",
    "# This will be a helper function that I use for filling in the na's for home_market_value with the median\n",
    "def parse_home_value(val):\n",
    "    if pd.isna(val):\n",
    "        return np.nan\n",
    "    val = str(val).strip()\n",
    "    if val.upper() == \"N/A\":\n",
    "        return np.nan\n",
    "    if \" - \" in val:\n",
    "        lo, hi = val.split(\" - \")\n",
    "        return (float(lo) + float(hi)) / 2\n",
    "    try:\n",
    "        return float(val)\n",
    "    except ValueError:\n",
    "        return np.nan  \n",
    "    \n",
    "# This will be a helper function for deleting all corresponding X/y indexes for rows with n/a's representing < 1 % of that column\n",
    "def drop_na_rows(X,y,column_name):\n",
    "    mask = X[column_name].notna()\n",
    "    return X[mask].copy(), y[mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc2e32a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Missing Values  Percentage\n",
      "DAYS_TENURE                       0    0.000000\n",
      "age_in_years                 167759    7.357047\n",
      "LATITUDE                     471474   20.676426\n",
      "LONGITUDE                    471474   20.676426\n",
      "CITY                          17006    0.745796\n",
      "income                       167759    7.357047\n",
      "HAS_CHILDREN                 167759    7.357047\n",
      "LENGTH_OF_RESIDENCE          167759    7.357047\n",
      "marital_status               599389   26.286121\n",
      "HOME_MARKET_VALUE            357953   15.697979\n",
      "HOME_OWNER                   167759    7.357047\n",
      "COLLEGE_DEGREE               167759    7.357047\n",
      "GOOD_CREDIT                  167759    7.357047\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAYS_TENURE</th>\n",
       "      <th>age_in_years</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>CITY</th>\n",
       "      <th>income</th>\n",
       "      <th>HAS_CHILDREN</th>\n",
       "      <th>LENGTH_OF_RESIDENCE</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>HOME_MARKET_VALUE</th>\n",
       "      <th>HOME_OWNER</th>\n",
       "      <th>COLLEGE_DEGREE</th>\n",
       "      <th>GOOD_CREDIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6291.0</td>\n",
       "      <td>66.387</td>\n",
       "      <td>32.964555</td>\n",
       "      <td>-96.819410</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>80372.176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.801</td>\n",
       "      <td>None</td>\n",
       "      <td>500000 - 749999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4496.0</td>\n",
       "      <td>58.968</td>\n",
       "      <td>32.964555</td>\n",
       "      <td>-96.819410</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>125000.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>Single</td>\n",
       "      <td>500000 - 749999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6291.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.600787</td>\n",
       "      <td>-97.101485</td>\n",
       "      <td>Mansfield</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6291.0</td>\n",
       "      <td>64.641</td>\n",
       "      <td>32.563342</td>\n",
       "      <td>-97.058826</td>\n",
       "      <td>Mansfield</td>\n",
       "      <td>70000.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.000</td>\n",
       "      <td>Married</td>\n",
       "      <td>125000 - 149999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>549.0</td>\n",
       "      <td>34.639</td>\n",
       "      <td>33.006625</td>\n",
       "      <td>-97.203735</td>\n",
       "      <td>Roanoke</td>\n",
       "      <td>87500.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000</td>\n",
       "      <td>Single</td>\n",
       "      <td>100000 - 124999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DAYS_TENURE  age_in_years   LATITUDE  LONGITUDE       CITY      income  \\\n",
       "1       6291.0        66.387  32.964555 -96.819410     Dallas   80372.176   \n",
       "2       4496.0        58.968  32.964555 -96.819410     Dallas  125000.000   \n",
       "3       6291.0           NaN  32.600787 -97.101485  Mansfield         NaN   \n",
       "4       6291.0        64.641  32.563342 -97.058826  Mansfield   70000.000   \n",
       "5        549.0        34.639  33.006625 -97.203735    Roanoke   87500.000   \n",
       "\n",
       "   HAS_CHILDREN  LENGTH_OF_RESIDENCE marital_status HOME_MARKET_VALUE  \\\n",
       "1           0.0                6.801           None   500000 - 749999   \n",
       "2           1.0                2.000         Single   500000 - 749999   \n",
       "3           NaN                  NaN           None              None   \n",
       "4           1.0                7.000        Married   125000 - 149999   \n",
       "5           0.0                3.000         Single   100000 - 124999   \n",
       "\n",
       "   HOME_OWNER  COLLEGE_DEGREE  GOOD_CREDIT  \n",
       "1         0.0             1.0          1.0  \n",
       "2         1.0             0.0          1.0  \n",
       "3         NaN             NaN          NaN  \n",
       "4         1.0             1.0          1.0  \n",
       "5         1.0             0.0          1.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset=['CURR_ANN_AMT']) # Drop the rows without curr_ann_amt\n",
    "df = df.dropna(subset=['INDIVIDUAL_ID']) # Drop the rows without individual_id's (Only 1 row for some reason)\n",
    "\n",
    "# Calling out the current annual amount as our predictor target\n",
    "y = df[['CURR_ANN_AMT']]\n",
    "\n",
    "# Specifying our features that we will be using for model fitting\n",
    "features = ['DAYS_TENURE','age_in_years','LATITUDE','LONGITUDE','CITY','income','HAS_CHILDREN','LENGTH_OF_RESIDENCE','marital_status','HOME_MARKET_VALUE','HOME_OWNER','COLLEGE_DEGREE','GOOD_CREDIT']\n",
    "X = df[features] \n",
    "\n",
    "# Take a peak at how the features matrix looks \n",
    "pd.set_option('display.max_columns',None)\n",
    "missing_summary(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4291db4f",
   "metadata": {},
   "source": [
    "Notes on missing data:\n",
    "-The AGE_IN_YEARS would be expected to be 0 since it is from the customer table (the primary table) but there are just nulls in their anyways despiste a COALESCE from the autoinsurance_churn file\n",
    "-The ACCT_SUSPD_DATE is lean since the termination file is lean on data but that predictor will not be used in modeling anyways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78a32c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JDECKE46\\AppData\\Local\\Temp\\ipykernel_40812\\886487437.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"HOME_MARKET_VALUE\"] = X[\"HOME_MARKET_VALUE\"].apply(parse_home_value)\n",
      "C:\\Users\\JDECKE46\\AppData\\Local\\Temp\\ipykernel_40812\\886487437.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"HOME_MARKET_VALUE\"] = X[\"HOME_MARKET_VALUE\"].fillna(overall_home_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Home Median : $112,499.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JDECKE46\\AppData\\Local\\Temp\\ipykernel_40812\\886487437.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"lat_median\"] = X[\"CITY\"].map(city_medians[\"LATITUDE\"])\n",
      "C:\\Users\\JDECKE46\\AppData\\Local\\Temp\\ipykernel_40812\\886487437.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"long_median\"] = X[\"CITY\"].map(city_medians[\"LONGITUDE\"])\n",
      "C:\\Users\\JDECKE46\\AppData\\Local\\Temp\\ipykernel_40812\\886487437.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"LATITUDE\"] = X[\"LATITUDE\"].fillna(X[\"lat_median\"])\n",
      "C:\\Users\\JDECKE46\\AppData\\Local\\Temp\\ipykernel_40812\\886487437.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"LONGITUDE\"] = X[\"LONGITUDE\"].fillna(X[\"long_median\"])\n",
      "C:\\Users\\JDECKE46\\AppData\\Local\\Temp\\ipykernel_40812\\886487437.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X['marital_status'] = X['marital_status'].replace({\"Single\":0,\"Married\":1})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Missing Values  Percentage\n",
      "DAYS_TENURE                               0         0.0\n",
      "age_in_years                              0         0.0\n",
      "LATITUDE                                  0         0.0\n",
      "LONGITUDE                                 0         0.0\n",
      "income                                    0         0.0\n",
      "HAS_CHILDREN                              0         0.0\n",
      "LENGTH_OF_RESIDENCE                       0         0.0\n",
      "marital_status                            0         0.0\n",
      "HOME_MARKET_VALUE                         0         0.0\n",
      "HOME_OWNER                                0         0.0\n",
      "COLLEGE_DEGREE                            0         0.0\n",
      "GOOD_CREDIT                               0         0.0\n",
      "lat_median                                0         0.0\n",
      "long_median                               0         0.0\n",
      "marital_status_missing                    0         0.0\n",
      "HAS_CHILDREN_missing                      0         0.0\n",
      "HOME_OWNER_missing                        0         0.0\n",
      "COLLEGE_DEGREE_missing                    0         0.0\n",
      "GOOD_CREDIT_missing                       0         0.0\n",
      "age_in_years_missing                      0         0.0\n",
      "income_missing                            0         0.0\n",
      "LENGTH_OF_RESIDENCE_missing               0         0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAYS_TENURE</th>\n",
       "      <th>age_in_years</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>income</th>\n",
       "      <th>HAS_CHILDREN</th>\n",
       "      <th>LENGTH_OF_RESIDENCE</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>HOME_MARKET_VALUE</th>\n",
       "      <th>HOME_OWNER</th>\n",
       "      <th>COLLEGE_DEGREE</th>\n",
       "      <th>GOOD_CREDIT</th>\n",
       "      <th>lat_median</th>\n",
       "      <th>long_median</th>\n",
       "      <th>marital_status_missing</th>\n",
       "      <th>HAS_CHILDREN_missing</th>\n",
       "      <th>HOME_OWNER_missing</th>\n",
       "      <th>COLLEGE_DEGREE_missing</th>\n",
       "      <th>GOOD_CREDIT_missing</th>\n",
       "      <th>age_in_years_missing</th>\n",
       "      <th>income_missing</th>\n",
       "      <th>LENGTH_OF_RESIDENCE_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6291.0</td>\n",
       "      <td>66.387</td>\n",
       "      <td>32.964555</td>\n",
       "      <td>-96.819410</td>\n",
       "      <td>80372.176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.801</td>\n",
       "      <td>0</td>\n",
       "      <td>624999.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.807488</td>\n",
       "      <td>-96.792844</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4496.0</td>\n",
       "      <td>58.968</td>\n",
       "      <td>32.964555</td>\n",
       "      <td>-96.819410</td>\n",
       "      <td>125000.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0</td>\n",
       "      <td>624999.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.807488</td>\n",
       "      <td>-96.792844</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6291.0</td>\n",
       "      <td>55.444</td>\n",
       "      <td>32.600787</td>\n",
       "      <td>-97.101485</td>\n",
       "      <td>80372.176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.801</td>\n",
       "      <td>0</td>\n",
       "      <td>112499.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.586145</td>\n",
       "      <td>-97.127821</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6291.0</td>\n",
       "      <td>64.641</td>\n",
       "      <td>32.563342</td>\n",
       "      <td>-97.058826</td>\n",
       "      <td>70000.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.000</td>\n",
       "      <td>1</td>\n",
       "      <td>137499.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.586145</td>\n",
       "      <td>-97.127821</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>549.0</td>\n",
       "      <td>34.639</td>\n",
       "      <td>33.006625</td>\n",
       "      <td>-97.203735</td>\n",
       "      <td>87500.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>112499.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.996025</td>\n",
       "      <td>-97.212322</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DAYS_TENURE  age_in_years   LATITUDE  LONGITUDE      income  HAS_CHILDREN  \\\n",
       "1       6291.0        66.387  32.964555 -96.819410   80372.176           0.0   \n",
       "2       4496.0        58.968  32.964555 -96.819410  125000.000           1.0   \n",
       "3       6291.0        55.444  32.600787 -97.101485   80372.176           0.0   \n",
       "4       6291.0        64.641  32.563342 -97.058826   70000.000           1.0   \n",
       "5        549.0        34.639  33.006625 -97.203735   87500.000           0.0   \n",
       "\n",
       "   LENGTH_OF_RESIDENCE  marital_status  HOME_MARKET_VALUE  HOME_OWNER  \\\n",
       "1                6.801               0           624999.5         0.0   \n",
       "2                2.000               0           624999.5         1.0   \n",
       "3                6.801               0           112499.5         0.0   \n",
       "4                7.000               1           137499.5         1.0   \n",
       "5                3.000               0           112499.5         1.0   \n",
       "\n",
       "   COLLEGE_DEGREE  GOOD_CREDIT  lat_median  long_median  \\\n",
       "1             1.0          1.0   32.807488   -96.792844   \n",
       "2             0.0          1.0   32.807488   -96.792844   \n",
       "3             0.0          0.0   32.586145   -97.127821   \n",
       "4             1.0          1.0   32.586145   -97.127821   \n",
       "5             0.0          1.0   32.996025   -97.212322   \n",
       "\n",
       "   marital_status_missing  HAS_CHILDREN_missing  HOME_OWNER_missing  \\\n",
       "1                       1                     0                   0   \n",
       "2                       0                     0                   0   \n",
       "3                       1                     1                   1   \n",
       "4                       0                     0                   0   \n",
       "5                       0                     0                   0   \n",
       "\n",
       "   COLLEGE_DEGREE_missing  GOOD_CREDIT_missing  age_in_years_missing  \\\n",
       "1                       0                    0                     0   \n",
       "2                       0                    0                     0   \n",
       "3                       1                    1                     1   \n",
       "4                       0                    0                     0   \n",
       "5                       0                    0                     0   \n",
       "\n",
       "   income_missing  LENGTH_OF_RESIDENCE_missing  \n",
       "1               0                            0  \n",
       "2               0                            0  \n",
       "3               1                            1  \n",
       "4               0                            0  \n",
       "5               0                            0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here will be my block of code for correcting out the na's and range values given for home_market_value\n",
    "X[\"HOME_MARKET_VALUE\"] = X[\"HOME_MARKET_VALUE\"].apply(parse_home_value)\n",
    "overall_home_median = X[\"HOME_MARKET_VALUE\"].median()\n",
    "print(\"Overall Home Median :\", f\"${overall_home_median:,.2f}\") # This will print out what the overall home median value is\n",
    "X[\"HOME_MARKET_VALUE\"] = X[\"HOME_MARKET_VALUE\"].fillna(overall_home_median)\n",
    "\n",
    "# We need to compute city-level medians for LATITUDE and LONGITUDE\n",
    "city_medians = X.groupby(\"CITY\")[[\"LATITUDE\",\"LONGITUDE\"]].median()\n",
    "\n",
    "# Map back these medians\n",
    "X[\"lat_median\"] = X[\"CITY\"].map(city_medians[\"LATITUDE\"])\n",
    "X[\"long_median\"] = X[\"CITY\"].map(city_medians[\"LONGITUDE\"])\n",
    "\n",
    "# Fill missing lat/long wiht city medians \n",
    "X[\"LATITUDE\"] = X[\"LATITUDE\"].fillna(X[\"lat_median\"])\n",
    "X[\"LONGITUDE\"] = X[\"LONGITUDE\"].fillna(X[\"long_median\"])\n",
    "\n",
    "# We can drop city now since we no longer need it\n",
    "X = X.drop(columns=['CITY'])\n",
    "\n",
    "# For missing marital_status we are going to put all the n/a's as 0's and add another column for marital_status_missing marked with a 1\n",
    "X['marital_status_missing'] = X['marital_status'].isna().astype(int)\n",
    "X['marital_status'] = X['marital_status'].fillna(0)\n",
    "X['marital_status'] = X['marital_status'].replace({\"Single\":0,\"Married\":1})\n",
    "\n",
    "## For the missing and n/a values for 'Has_Children', 'Home_Owner', 'College_Degree', and 'Good_Credit': since the missing values only represent 7% of the dataset, let's put in a \"Is_missing\" category to see if missingness correlates with premiums.\n",
    "for col in ['HAS_CHILDREN','HOME_OWNER','COLLEGE_DEGREE','GOOD_CREDIT']:\n",
    "    X[col + '_missing'] = X[col].isna().astype(int)\n",
    "    X[col] = X[col].fillna(0)\n",
    "\n",
    "## For age, income, and length of residence: fill in the missing values with the median values\n",
    "for col in ['age_in_years','income','LENGTH_OF_RESIDENCE']:\n",
    "    X[col + '_missing'] = X[col].isna().astype(int)\n",
    "    X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "X, y = drop_na_rows(X,y,\"marital_status\")\n",
    "X, y = drop_na_rows(X,y,\"LATITUDE\")\n",
    "X, y = drop_na_rows(X,y,\"LONGITUDE\")\n",
    "X, y = drop_na_rows(X,y,\"lat_median\")\n",
    "X, y = drop_na_rows(X,y,\"long_median\")\n",
    "\n",
    "\n",
    "\n",
    "# Take a peak at how the features matrix looks \n",
    "pd.set_option('display.max_columns',None)\n",
    "missing_summary(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f7ee9d",
   "metadata": {},
   "source": [
    "For missing values, let's implement a \"was_missing\" feature so the model can learn if missingness correlates with premiums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a354878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(DB_PATH)\n",
    "\n",
    "y.to_sql(\"y\",conn,if_exists=\"replace\",index=False)\n",
    "X.to_sql(\"X\",conn,if_exists=\"replace\",index=False)\n",
    "\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
